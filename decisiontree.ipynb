{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Decision Trees for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_original = pd.read_excel(\"./Datasets/Filtered_features.xlsx\")\n",
    "X_pca = pd.read_excel(\"./Datasets/PCA_features.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sepertaing the Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = X_original[\"Churn Value\"]\n",
    "y_pca = X_pca[\"Churn Value\"]\n",
    "\n",
    "features_original = X_original.drop(columns=[\"Churn Value\"])\n",
    "features_pca = X_pca.drop(columns=[\"Churn Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Data into Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(features_original, y_original, test_size=0.33, random_state=2)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(features_pca, y_pca, test_size=0.33, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Fitting Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_original = DecisionTreeClassifier(random_state=2)\n",
    "dt_original.fit(X_train_original, y_train_original)\n",
    "original_predicted = dt_original.predict(X_test_original)\n",
    "\n",
    "dt_pca = DecisionTreeClassifier(random_state=2)\n",
    "dt_pca.fit(X_train_pca, y_train_pca)\n",
    "pca_predicted = dt_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the model\n",
    "- on the basis of Accuracy\n",
    "- on the basis of Precision\n",
    "- on the basis of Recall\n",
    "- on the basis of F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (with original features): \n",
      "0.7371822490305903 \n",
      "\n",
      "Precision Score (with original features): \n",
      "0.5168350168350169 \n",
      "\n",
      "Recall Score (with original features): \n",
      "0.4873015873015873 \n",
      "\n",
      "F1 Score (with original features): \n",
      "0.5016339869281046 \n",
      " \n",
      "\n",
      "Accuracy Score (with pca features): \n",
      "0.7147781128823782 \n",
      "\n",
      "Precision Score (with pca features): \n",
      "0.4750778816199377 \n",
      "\n",
      "Recall Score (with pca features): \n",
      "0.48412698412698413 \n",
      "\n",
      "F1 Score (with pca features): \n",
      "0.4795597484276729 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# for original features\n",
    "print(\"Accuracy Score (with original features): \")\n",
    "print(accuracy_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"Precision Score (with original features): \")\n",
    "print(precision_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"Recall Score (with original features): \")\n",
    "print(recall_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"F1 Score (with original features): \")\n",
    "print(f1_score(y_test_original, original_predicted), \"\\n\", \"\\n\")\n",
    "\n",
    "# for pca features\n",
    "print(\"Accuracy Score (with pca features): \")\n",
    "print(accuracy_score(y_test_pca, pca_predicted), \"\\n\")\n",
    "print(\"Precision Score (with pca features): \")\n",
    "print(precision_score(y_test_pca, pca_predicted), \"\\n\")\n",
    "print(\"Recall Score (with pca features): \")\n",
    "print(recall_score(y_test_pca, pca_predicted), \"\\n\")\n",
    "print(\"F1 Score (with pca features): \")\n",
    "print(f1_score(y_test_pca, pca_predicted), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (with original features): \n",
      "0.7371822490305903 \n",
      "\n",
      "Precision Score (with original features): \n",
      "0.5166112956810631 \n",
      "\n",
      "Recall Score (with original features): \n",
      "0.4936507936507937 \n",
      "\n",
      "F1 Score (with original features): \n",
      "0.5048701298701299 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_original_features_train = X_train_original[['Partner', 'Dependents', 'Tech Support', 'Paperless Billing', 'Monthly Charges', 'Total Charges', 'DSL_Service', 'month-to-month_contract', 'one-year_contract', 'two-year_contract', 'bank-transfer-auto_paymentmethod', 'credit-card-auto_paymentmethod', 'electronic-check_paymentmethod']]\n",
    "new_original_features_test = X_test_original[['Partner', 'Dependents', 'Tech Support', 'Paperless Billing', 'Monthly Charges', 'Total Charges', 'DSL_Service', 'month-to-month_contract', 'one-year_contract', 'two-year_contract', 'bank-transfer-auto_paymentmethod', 'credit-card-auto_paymentmethod', 'electronic-check_paymentmethod']]\n",
    "dt_original.fit(new_original_features_train, y_train_original)\n",
    "original_predicted = dt_original.predict(new_original_features_test)\n",
    "# for original features\n",
    "print(\"Accuracy Score (with original features): \")\n",
    "print(accuracy_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"Precision Score (with original features): \")\n",
    "print(precision_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"Recall Score (with original features): \")\n",
    "print(recall_score(y_test_original, original_predicted), \"\\n\")\n",
    "print(\"F1 Score (with original features): \")\n",
    "print(f1_score(y_test_original, original_predicted), \"\\n\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
